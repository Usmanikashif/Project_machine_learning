{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95693d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f99ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datacsv Directory for all the dataset (A,B,C,D, and E) if don't exist\n",
    "\n",
    "os.makedirs('H:/Final_project/Data/Data_csv/A/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/Data_csv/B/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/Data_csv/C/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/Data_csv/D/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/Data_csv/E/',exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386712e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunk Directory for all the dataset (A,B,C,D, and E) if don't exist\n",
    "\n",
    "for num_files in range(1,101):\n",
    "    os.makedirs(os.path.join('H:/Final_project/Data/chunk/A/' + str(num_files)),exist_ok = True)\n",
    "    os.makedirs(os.path.join('H:/Final_project/Data/chunk/B/' + str(num_files)),exist_ok = True)\n",
    "    os.makedirs(os.path.join('H:/Final_project/Data/chunk/C/' + str(num_files)),exist_ok = True)\n",
    "    os.makedirs(os.path.join('H:/Final_project/Data/chunk/D/' + str(num_files)),exist_ok = True)\n",
    "    os.makedirs(os.path.join('H:/Final_project/Data/chunk/E/' + str(num_files)),exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2ba361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merged Directory for all the dataset (A,B,C,D, and E) if don't exist\n",
    "\n",
    "os.makedirs('H:/Final_project/Data/merged/A/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/merged/B/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/merged/C/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/merged/D/',exist_ok = True)\n",
    "os.makedirs('H:/Final_project/Data/merged/E/',exist_ok = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f706beeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccc86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We downloaded the dataset using the given link https://repositori.upf.edu/handle/10230/42894\n",
    "# The datasets contain file name A, B, C, D, and E\n",
    "\n",
    "# We changed the format file txt to csv\n",
    "#Each dataset contains 100-single channel EEG segments with duration of 23.6 seconds and \n",
    "#the corresponding time series is sampled into 4097 data points. \n",
    "\n",
    "# Folder A\n",
    "path1A = r'H:/Final_project/Data/Raw_data/A'\n",
    "path2A = r'H:/Final_project/Data/Data_csv/A'\n",
    "for i in range(1,101):\n",
    "    fileA = pd.read_csv(os.path.join(path1A,(str(i)+ \".txt\")))\n",
    "    fileA = fileA.drop(labels=[0,1])\n",
    "    new_csv_fileA = fileA.to_csv(os.path.join(path2A, (str(i) + \".csv\")),index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "# Folder B\n",
    "\n",
    "path1B = r'H:/Final_project/Data/Raw_data/B'\n",
    "path2B = r'H:/Final_project/Data/Data_csv/B'\n",
    "for i in range(1,101):\n",
    "    fileB = pd.read_csv(os.path.join(path1B,(str(i)+ \".txt\")))\n",
    "    fileB = fileB.drop(labels=[0,1])\n",
    "    new_csv_fileB = fileB.to_csv(os.path.join(path2B, (str(i) + \".csv\")),index=False)\n",
    "    \n",
    "    \n",
    "# Folder C\n",
    "\n",
    "path1C = r'H:/Final_project/Data/Raw_data/C'\n",
    "path2C = r'H:/Final_project/Data/Data_csv/C'\n",
    "for i in range(1,101):\n",
    "    fileC = pd.read_csv(os.path.join(path1C,(str(i)+ \".txt\")))\n",
    "    fileC = fileC.drop(labels=[4094,4095])\n",
    "    new_csv_fileC = fileC.to_csv(os.path.join(path2C, (str(i) + \".csv\")),index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "# Folder D\n",
    "\n",
    "path1D = r'H:/Final_project/Data/Raw_data/D'\n",
    "path2D = r'H:/Final_project/Data/Data_csv/D'\n",
    "for i in range(1,101):\n",
    "    fileD = pd.read_csv(os.path.join(path1D,(str(i)+ \".txt\")))\n",
    "    fileD = fileD.drop(labels=[0,1])\n",
    "    new_csv_fileD = fileD.to_csv(os.path.join(path2D, (str(i) + \".csv\")),index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "# Folder E\n",
    "\n",
    "path1E = r'H:/Final_project/Data/Raw_data/E'\n",
    "path2E = r'H:/Final_project/Data/Data_csv/E'\n",
    "for i in range(1,101):\n",
    "    fileE = pd.read_csv(os.path.join(path1E,(str(i)+ \".txt\")))\n",
    "    fileE = fileE.drop(labels=[0,1])\n",
    "    new_csv_fileE = fileE.to_csv(os.path.join(path2E, (str(i) + \".csv\")),index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d265b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4094, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'H:/Final_project/Data/Data_csv/A/1.csv')\n",
    "df1.shape\n",
    "#After reshaping each file contain 4094 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cbbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saved the data into a folder and then divide each files into 23 chunk and each contains 178 datapoints for 1 second. \n",
    "#finally merged the 23 chunk file into a single file \n",
    "\n",
    "\n",
    "# Merged folder A\n",
    "\n",
    "filenameA =r'H:/Final_project/Data/Data_csv/A'\n",
    "out_pathA = r'H:/Final_project/Data/Chunk/A/'\n",
    "merged_pathA = r'H:/Final_project/Data/merged/A'\n",
    "for num_files in range (1,101):\n",
    "    fileA = pd.read_csv(os.path.join(filenameA,(str(num_files)+ \".csv\")))\n",
    "    dir_pathA = os.path.join(out_pathA +str(num_files)+'/')\n",
    "    j =0\n",
    "    for i in range(len(fileA)):\n",
    "        if i % 178 == 0:\n",
    "            j = j+1\n",
    "            fileA[i:i+178].to_csv(os.path.join(dir_pathA, (str(j) + \".csv\")),index=False)\n",
    "    \n",
    "    dir_mergedpathA = os.path.join(merged_pathA +'/')\n",
    "    allmerged_filesA =glob.glob(out_pathA + str(num_files)+'/'+ \"/*.csv\") \n",
    "    df_from_each_fileA = (pd.read_csv(f, sep=',').transpose() for f in allmerged_filesA)\n",
    "    df_mergedA   = pd.concat(df_from_each_fileA, ignore_index=True)\n",
    "    df_mergedA.to_csv(os.path.join(merged_pathA, (str(num_files) + \".csv\")),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d61fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged folder B\n",
    "filenameB =r'H:/Final_project/Data/Data_csv/B'\n",
    "out_pathB = r'H:/Final_project/Data/Chunk/B/'\n",
    "merged_pathB = r'H:/Final_project/Data/merged/B'\n",
    "for num_files in range (1,101):\n",
    "    fileB = pd.read_csv(os.path.join(filenameB,(str(num_files)+ \".csv\")))\n",
    "    #fileB = fileB.drop(columns=['Unnamed: 0'])\n",
    "    dir_pathB = os.path.join(out_pathB +str(num_files)+'/')\n",
    "    j =0\n",
    "    for i in range(len(fileB)):\n",
    "        if i % 178 == 0:\n",
    "            j = j+1\n",
    "            fileB[i:i+178].to_csv(os.path.join(dir_pathB, (str(j) + \".csv\")),index=False)\n",
    "    \n",
    "    dir_mergedpathB = os.path.join(merged_pathB +'/')\n",
    "    allmerged_filesB =glob.glob(out_pathB + str(num_files)+'/'+ \"/*.csv\") \n",
    "    df_from_each_fileB = (pd.read_csv(f, sep=',').transpose() for f in allmerged_filesB)\n",
    "    df_mergedB   = pd.concat(df_from_each_fileB, ignore_index=True)\n",
    "    df_mergedB.to_csv(os.path.join(merged_pathB, (str(num_files) + \".csv\")),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9be9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged folder C\n",
    "filenameC =r'H:/Final_project/Data/Data_csv/C'\n",
    "out_pathC = r'H:/Final_project/Data/Chunk/C/'\n",
    "merged_pathC = r'H:/Final_project/Data/merged/C'\n",
    "for num_files in range (1,101):\n",
    "    fileC = pd.read_csv(os.path.join(filenameC,(str(num_files)+ \".csv\")))\n",
    "    #fileC = fileC.drop(columns=['Unnamed: 0'])\n",
    "    dir_pathC = os.path.join(out_pathC +str(num_files)+'/')\n",
    "    j =0\n",
    "    for i in range(len(fileC)):\n",
    "        if i % 178 == 0:\n",
    "            j = j+1\n",
    "            fileC[i:i+178].to_csv(os.path.join(dir_pathC, (str(j) + \".csv\")),index=False)\n",
    "    \n",
    "    dir_mergedpathC = os.path.join(merged_pathC +'/')\n",
    "    allmerged_filesC =glob.glob(out_pathC + str(num_files)+'/'+ \"/*.csv\") \n",
    "    df_from_each_fileC = (pd.read_csv(f, sep=',').transpose() for f in allmerged_filesC)\n",
    "    df_mergedC   = pd.concat(df_from_each_fileC, ignore_index=True)\n",
    "    df_mergedC.to_csv(os.path.join(merged_pathC, (str(num_files) + \".csv\")),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58610136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged folder D\n",
    "\n",
    "filenameD =r'H:/Final_project/Data/Data_csv/D'\n",
    "out_pathD = r'H:/Final_project/Data/Chunk/D/'\n",
    "merged_pathD = r'H:/Final_project/Data/merged/D'\n",
    "for num_files in range (1,101):\n",
    "    fileD = pd.read_csv(os.path.join(filenameD,(str(num_files)+ \".csv\")))\n",
    "    #fileD = fileD.drop(columns=['Unnamed: 0'])\n",
    "    dir_pathD = os.path.join(out_pathD +str(num_files)+'/')\n",
    "    j =0\n",
    "    for i in range(len(fileD)):\n",
    "        if i % 178 == 0:\n",
    "            j = j+1\n",
    "            fileD[i:i+178].to_csv(os.path.join(dir_pathD, (str(j) + \".csv\")),index=False)\n",
    "    \n",
    "    dir_mergedpathD = os.path.join(merged_pathD +'/')\n",
    "    allmerged_filesD =glob.glob(out_pathD + str(num_files)+'/'+ \"/*.csv\") \n",
    "    df_from_each_fileD = (pd.read_csv(f, sep=',').transpose() for f in allmerged_filesD)\n",
    "    df_mergedD   = pd.concat(df_from_each_fileD, ignore_index=True)\n",
    "    df_mergedD.to_csv(os.path.join(merged_pathD, (str(num_files) + \".csv\")),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a68f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged folder E\n",
    "\n",
    "filenameE =r'H:/Final_project/Data/Data_csv/E'\n",
    "out_pathE = r'H:/Final_project/Data/Chunk/E/'\n",
    "merged_pathE = r'H:/Final_project/Data/merged/E'\n",
    "for num_files in range (1,101):\n",
    "    fileE = pd.read_csv(os.path.join(filenameE,(str(num_files)+ \".csv\")))\n",
    "    #fileE = fileE.drop(columns=['Unnamed: 0'])\n",
    "    dir_pathE = os.path.join(out_pathE +str(num_files)+'/')\n",
    "    j =0\n",
    "    for i in range(len(fileE)):\n",
    "        if i % 178 == 0:\n",
    "            j = j+1\n",
    "            fileE[i:i+178].to_csv(os.path.join(dir_pathE, (str(j) + \".csv\")),index=False)\n",
    "    \n",
    "    dir_mergedpathE = os.path.join(merged_pathE +'/')\n",
    "    allmerged_filesE =glob.glob(out_pathE + str(num_files)+'/'+ \"/*.csv\") \n",
    "    df_from_each_fileE = (pd.read_csv(f, sep=',').transpose() for f in allmerged_filesE)\n",
    "    df_mergedE   = pd.concat(df_from_each_fileE, ignore_index=True)\n",
    "    df_mergedE.to_csv(os.path.join(merged_pathE, (str(num_files) + \".csv\")),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b92c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
